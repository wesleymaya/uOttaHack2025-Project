#TODO
import json
import llama_chain
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import uvicorn
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI()

# Configure CORS for the FastAPI app
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # Adjust based on frontend domain
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Define a data model for request validation
class DataModel(BaseModel):
    message: str

def get_api(filename="config.json"):
    """
    Reads and returns the API key from a JSON config file.
    
    Parameters:
        filename (str): Path to the config JSON file.
                       Defaults to "config.json".
    
    Returns:
        tuple: The Grok and ElevenLabs API keys (returns empty strings if not found).
    """
    try:
        with open(filename, "r") as file:
            config = json.load(file)
        return config.get("grok_api_key", ""), config.get("elevenlabs_api_key", "")
    except (FileNotFoundError, json.JSONDecodeError):
        print(f"Error: Could not read or parse {filename}.")
        return "", ""

@app.post("/getdata")
async def receive_data(data: DataModel):
    """
    Endpoint to receive data from the front end and process it with llama_chain.

    Parameters:
        data (DataModel): Input data containing a message.
    
    Returns:
        dict: Response generated by llama_chain.
    """
    print(f"Received data: {data.message}")
    answer = llama_chain.parse_budget(data.message)
    return answer

if __name__ == "__main__":
    print("Starting API server...")
    uvicorn.run(app, host="0.0.0.0", port=8000)
